{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx62LDlPWjGG"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Notebook section: 1.3.10 Feature evaluation and refinement\n",
        "Team 102D · AB Data Challenge — Iteration 2\n",
        "\n",
        "This script follows after 1.3.9 (Feature Engineering Implementation).\n",
        "It loads results/iteration_2/features_v2.csv and performs:\n",
        "\n",
        "1.3.10.1 Identification of relevant and non‑redundant features\n",
        "  • Basic filters: missingness, zero/low variance\n",
        "  • Univariate signals: point-biserial correlation, MI, single‑feature AUC\n",
        "  • Redundancy pruning: correlation-based clustering/greedy removal\n",
        "  • Model-based importance (LightGBM → fallback to RF / L1-LogReg)\n",
        "  • Optional VIF for multi-collinearity diagnostics (slow; disabled by default)\n",
        "\n",
        "1.3.10.2 Summary of selected features for modeling\n",
        "  • Persist: selected_features.txt, feature_importances.csv, redundancy_pairs.csv\n",
        "  • Report: feature_selection_report.md (human-readable summary)\n",
        "\n",
        "Safe to run even if LightGBM isn’t installed.\n",
        "\"\"\"\n",
        "\n",
        "# === Imports & setup ===\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Optional: LightGBM if available\n",
        "try:\n",
        "    import lightgbm as lgb  # type: ignore\n",
        "    _HAS_LGB = True\n",
        "except Exception:\n",
        "    _HAS_LGB = False\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# === Paths ===\n",
        "PROJECT_ROOT = \".\"\n",
        "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\")\n",
        "RESULTS_DIR = os.path.join(PROJECT_ROOT, \"results\", \"iteration_2\")\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "FEATS_CSV = os.path.join(RESULTS_DIR, \"features_v2.csv\")\n",
        "\n",
        "print(\"Looking for features:\", FEATS_CSV)\n",
        "if not os.path.exists(FEATS_CSV):\n",
        "    raise SystemExit(\"features_v2.csv not found. Run 1.3.9 first.\")\n",
        "\n",
        "# === Load ===\n",
        "df = pd.read_csv(FEATS_CSV, low_memory=False)\n",
        "print(\"Loaded features:\", df.shape)\n",
        "\n",
        "# === Columns & label ===\n",
        "ID_CANDIDATES = [\"num_serie_contador\", \"polissa_id\"]\n",
        "TIME_COLS = [\"datetime\", \"date\", \"data_inici\", \"data_fi\", \"year\", \"month\", \"dayofweek\", \"hour\"]\n",
        "LABEL = \"y_anom\" if \"y_anom\" in df.columns else None\n",
        "\n",
        "id_col = None\n",
        "for c in ID_CANDIDATES:\n",
        "    if c in df.columns:\n",
        "        id_col = c\n",
        "        break\n",
        "\n",
        "# === Helper: choose numeric feature set (excludes IDs, time, labels) ===\n",
        "EXCLUDE = set((ID_CANDIDATES + TIME_COLS + [\"codi_anomalia\", \"meter_mean\", \"meter_std\"]))\n",
        "if LABEL:\n",
        "    EXCLUDE.add(LABEL)\n",
        "\n",
        "num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c]) and c not in EXCLUDE]\n",
        "if not num_cols:\n",
        "    raise SystemExit(\"No numeric feature columns found after exclusions.\")\n",
        "\n",
        "print(f\"Numeric feature candidates: {len(num_cols)}\")\n",
        "\n",
        "# === Basic diagnostics ===\n",
        "miss_ratio = df[num_cols].isna().mean().sort_values(ascending=False)\n",
        "zero_var = [c for c in num_cols if df[c].std(skipna=True) == 0]\n",
        "\n",
        "print(f\"Zero-variance features: {len(zero_var)}\")\n",
        "\n",
        "# Persist basic stats\n",
        "miss_ratio.to_csv(os.path.join(RESULTS_DIR, \"fs_missingness.csv\"))\n",
        "pd.Series(zero_var, name=\"zero_var_features\").to_csv(os.path.join(RESULTS_DIR, \"fs_zero_variance.csv\"), index=False)\n",
        "\n",
        "# Remove obviously bad ones now\n",
        "usable = [c for c in num_cols if c not in zero_var and miss_ratio.get(c, 0.0) < 0.99]\n",
        "print(f\"Usable after basic filters: {len(usable)}\")\n",
        "\n",
        "# === Unsupervised low-variance threshold (optional mild) ===\n",
        "VAR_THRESH = 1e-10\n",
        "low_var = [c for c in usable if df[c].var(skipna=True) <= VAR_THRESH]\n",
        "usable = [c for c in usable if c not in low_var]\n",
        "if low_var:\n",
        "    pd.Series(low_var, name=\"low_var_features\").to_csv(os.path.join(RESULTS_DIR, \"fs_low_variance.csv\"), index=False)\n",
        "print(f\"Usable after low-var filter: {len(usable)}\")\n",
        "\n",
        "# === Supervised signals (only if label present) ===\n",
        "results = {}\n",
        "if LABEL is not None and df[LABEL].notna().any():\n",
        "    y = df[LABEL].astype(int)\n",
        "\n",
        "    # Point-biserial (Pearson) correlation with label\n",
        "    def safe_corr(x: pd.Series, y: pd.Series) -> float:\n",
        "        s = pd.concat([x, y], axis=1).dropna()\n",
        "        if len(s) < 50 or s.iloc[:,0].std(ddof=1) == 0 or s.iloc[:,1].std(ddof=1) == 0:\n",
        "            return np.nan\n",
        "        return float(s.iloc[:,0].corr(s.iloc[:,1]))\n",
        "\n",
        "    corr_with_y = {c: safe_corr(df[c], y) for c in usable}\n",
        "\n",
        "    # Mutual information\n",
        "    X_mi = df[usable].copy()\n",
        "    imputer = SimpleImputer(strategy=\"median\")\n",
        "    X_mi = imputer.fit_transform(X_mi)\n",
        "    mi_vals = mutual_info_classif(X_mi, y, discrete_features=False, random_state=42)\n",
        "    mi_series = pd.Series(mi_vals, index=usable)\n",
        "\n",
        "    # Single-feature AUC (using raw values as scores)\n",
        "    auc_vals = {}\n",
        "    for c in usable:\n",
        "        s = pd.concat([df[c], y], axis=1).dropna()\n",
        "        if s[LABEL].nunique() < 2:\n",
        "            auc_vals[c] = np.nan\n",
        "            continue\n",
        "        try:\n",
        "            auc_vals[c] = roc_auc_score(s[LABEL], s[c])\n",
        "        except Exception:\n",
        "            auc_vals[c] = np.nan\n",
        "    auc_series = pd.Series(auc_vals)\n",
        "\n",
        "    # Persist univariate metrics\n",
        "    uni_df = pd.DataFrame({\n",
        "        \"feature\": usable,\n",
        "        \"corr_y\": [corr_with_y.get(c) for c in usable],\n",
        "        \"mutual_info\": [mi_series.get(c, np.nan) for c in usable],\n",
        "        \"auc_uni\": [auc_series.get(c, np.nan) for c in usable],\n",
        "        \"missing_ratio\": [miss_ratio.get(c, np.nan) for c in usable],\n",
        "        \"variance\": [df[c].var(skipna=True) for c in usable],\n",
        "    }).sort_values([\"mutual_info\"], ascending=False)\n",
        "    uni_df.to_csv(os.path.join(RESULTS_DIR, \"fs_univariate_metrics.csv\"), index=False)\n",
        "\n",
        "    # === Redundancy pruning (correlation-based) ===\n",
        "    # Use pairwise Pearson on imputed data\n",
        "    X_imp = pd.DataFrame(imputer.fit_transform(df[usable]), columns=usable)\n",
        "    corr_mat = X_imp.corr().abs()\n",
        "    np.fill_diagonal(corr_mat.values, 0.0)\n",
        "\n",
        "    REDUNDANCY_THRESH = 0.95\n",
        "    to_drop = set()\n",
        "    pairs = []\n",
        "\n",
        "    # Greedy: for each high-corr pair, drop the one with lower MI (fallback to lower variance)\n",
        "    cols_sorted = list(usable)\n",
        "    for i, a in enumerate(cols_sorted):\n",
        "        if a in to_drop:\n",
        "            continue\n",
        "        high = corr_mat.index[(corr_mat.loc[a] >= REDUNDANCY_THRESH)].tolist()\n",
        "        for b in high:\n",
        "            if b == a or b in to_drop:\n",
        "                continue\n",
        "            mia = float(mi_series.get(a, 0.0))\n",
        "            mib = float(mi_series.get(b, 0.0))\n",
        "            vara = float(df[a].var(skipna=True))\n",
        "            varb = float(df[b].var(skipna=True))\n",
        "            drop_b = mib < mia if not (math.isnan(mia) or math.isnan(mib)) else (varb < vara)\n",
        "            drop = b if drop_b else a\n",
        "            keep = a if drop_b else b\n",
        "            to_drop.add(drop)\n",
        "            pairs.append({\"a\": a, \"b\": b, \"corr\": float(corr_mat.loc[a, b]), \"kept\": keep, \"dropped\": drop})\n",
        "\n",
        "    red_pairs = pd.DataFrame(pairs)\n",
        "    if not red_pairs.empty:\n",
        "        red_pairs.sort_values(\"corr\", ascending=False).to_csv(os.path.join(RESULTS_DIR, \"fs_redundant_pairs.csv\"), index=False)\n",
        "\n",
        "    pruned = [c for c in usable if c not in to_drop]\n",
        "    print(f\"After redundancy pruning @ {REDUNDANCY_THRESH}: {len(pruned)} (dropped {len(to_drop)})\")\n",
        "\n",
        "    # === Model-based importance (cross-validated) ===\n",
        "    groups = df[id_col] if id_col is not None else None\n",
        "    n_splits = 5\n",
        "    splitter = GroupKFold(n_splits=n_splits) if groups is not None else StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    feat_importances = []\n",
        "    perm_rows = []\n",
        "\n",
        "    # Choose model\n",
        "    if _HAS_LGB:\n",
        "        model_name = \"LightGBM\"\n",
        "    else:\n",
        "        model_name = \"RandomForest\"\n",
        "\n",
        "    print(f\"Model for importance: {model_name}\")\n",
        "\n",
        "    for fold, (tr, va) in enumerate(splitter.split(df, y, groups) if groups is not None else splitter.split(df, y), 1):\n",
        "        X_tr = df.iloc[tr][pruned]\n",
        "        X_va = df.iloc[va][pruned]\n",
        "        y_tr = y.iloc[tr]\n",
        "        y_va = y.iloc[va]\n",
        "\n",
        "        X_tr_imp = imputer.fit_transform(X_tr)\n",
        "        X_va_imp = imputer.transform(X_va)\n",
        "\n",
        "        if _HAS_LGB:\n",
        "            clf = lgb.LGBMClassifier(\n",
        "                n_estimators=600,\n",
        "                learning_rate=0.03,\n",
        "                max_depth=-1,\n",
        "                subsample=0.9,\n",
        "                colsample_bytree=0.9,\n",
        "                reg_alpha=0.0,\n",
        "                reg_lambda=0.0,\n",
        "                random_state=42,\n",
        "                n_jobs=-1,\n",
        "                class_weight=\"balanced\"\n",
        "            )\n",
        "            clf.fit(X_tr_imp, y_tr, eval_set=[(X_va_imp, y_va)], eval_metric=\"auc\", verbose=False)\n",
        "            imp = clf.booster_.feature_importance(importance_type=\"gain\")\n",
        "        else:\n",
        "            clf = RandomForestClassifier(\n",
        "                n_estimators=600,\n",
        "                max_depth=None,\n",
        "                min_samples_leaf=1,\n",
        "                n_jobs=-1,\n",
        "                class_weight=\"balanced_subsample\",\n",
        "                random_state=42,\n",
        "            )\n",
        "            clf.fit(X_tr_imp, y_tr)\n",
        "            imp = clf.feature_importances_\n",
        "\n",
        "        auc_val = roc_auc_score(y_va, clf.predict_proba(X_va_imp)[:,1])\n",
        "        print(f\"  Fold {fold}/{n_splits} AUC = {auc_val:.4f}\")\n",
        "\n",
        "        feat_importances.append(pd.Series(imp, index=pruned, name=f\"fold{fold}\"))\n",
        "\n",
        "        # Permutation importance on validation fold (fast-ish)\n",
        "        perm = permutation_importance(clf, X_va_imp, y_va, n_repeats=5, random_state=42, n_jobs=-1, scoring=\"roc_auc\")\n",
        "        perm_rows.append(pd.Series(perm.importances_mean, index=pruned, name=f\"perm_fold{fold}\"))\n",
        "\n",
        "    imp_df = pd.concat(feat_importances, axis=1)\n",
        "    imp_df[\"mean_importance\"] = imp_df.mean(axis=1)\n",
        "    imp_df[\"std_importance\"] = imp_df.std(axis=1)\n",
        "    imp_df = imp_df.sort_values(\"mean_importance\", ascending=False)\n",
        "    imp_df.to_csv(os.path.join(RESULTS_DIR, \"fs_model_importances.csv\"))\n",
        "\n",
        "    perm_df = pd.concat(perm_rows, axis=1)\n",
        "    perm_df[\"mean_perm\"] = perm_df.mean(axis=1)\n",
        "    perm_df[\"std_perm\"] = perm_df.std(axis=1)\n",
        "    perm_df = perm_df.sort_values(\"mean_perm\", ascending=False)\n",
        "    perm_df.to_csv(os.path.join(RESULTS_DIR, \"fs_permutation_importances.csv\"))\n",
        "\n",
        "    # === Combine signals into a single score ===\n",
        "    # Normalize each metric to [0,1] via rank, then average\n",
        "    def rank01(s: pd.Series) -> pd.Series:\n",
        "        s = s.fillna(-np.inf)\n",
        "        r = s.rank(method=\"average\", ascending=False)\n",
        "        return (r - r.min()) / (r.max() - r.min() + 1e-9)\n",
        "\n",
        "    combo = pd.DataFrame(index=pruned)\n",
        "    combo[\"mi_r\"] = rank01(mi_series.reindex(pruned))\n",
        "    combo[\"auc_r\"] = rank01(auc_series.reindex(pruned))\n",
        "    combo[\"corr_r\"] = rank01(pd.Series(corr_with_y).reindex(pruned).abs())\n",
        "    combo[\"imp_r\"] = rank01(imp_df[\"mean_importance\"].reindex(pruned))\n",
        "    combo[\"perm_r\"] = rank01(perm_df[\"mean_perm\"].reindex(pruned))\n",
        "    combo[\"missing_penalty\"] = 1.0 - miss_ratio.reindex(pruned).fillna(0.0).clip(0, 1)\n",
        "\n",
        "    combo[\"score\"] = (\n",
        "        0.30 * combo[\"imp_r\"] +\n",
        "        0.20 * combo[\"perm_r\"] +\n",
        "        0.20 * combo[\"mi_r\"] +\n",
        "        0.15 * combo[\"auc_r\"] +\n",
        "        0.10 * combo[\"corr_r\"] +\n",
        "        0.05 * combo[\"missing_penalty\"]\n",
        "    )\n",
        "\n",
        "    combo = combo.sort_values(\"score\", ascending=False)\n",
        "    combo.to_csv(os.path.join(RESULTS_DIR, \"fs_combined_scores.csv\"))\n",
        "\n",
        "    # === Gatekeeping: must-pass thresholds (very mild) ===\n",
        "    GATE_MI = 0.0005\n",
        "    GATE_AUC = 0.53\n",
        "    GATE_CORR = 0.02\n",
        "\n",
        "    gates = (\n",
        "        (mi_series.reindex(pruned).fillna(0.0) >= GATE_MI) |\n",
        "        (auc_series.reindex(pruned).fillna(0.0) >= GATE_AUC) |\n",
        "        (pd.Series(corr_with_y).reindex(pruned).abs().fillna(0.0) >= GATE_CORR)\n",
        "    )\n",
        "\n",
        "    candidates = combo[gates].copy()\n",
        "\n",
        "    # Cap final selection size for first pass (tuneable)\n",
        "    TOP_K = min(60, len(candidates))\n",
        "    selected = candidates.head(TOP_K).index.tolist()\n",
        "\n",
        "    # Persist selections & summaries\n",
        "    with open(os.path.join(RESULTS_DIR, \"selected_features_v1.txt\"), \"w\") as f:\n",
        "        for c in selected:\n",
        "            f.write(c + \"\\n\")\n",
        "\n",
        "    summary = {\n",
        "        \"n_total_numeric\": int(len(num_cols)),\n",
        "        \"n_after_basic_filters\": int(len(usable)),\n",
        "        \"n_after_redundancy\": int(len(pruned)),\n",
        "        \"n_selected\": int(len(selected)),\n",
        "        \"model\": model_name,\n",
        "        \"redundancy_threshold\": REDUNDANCY_THRESH,\n",
        "        \"gates\": {\"mi\": GATE_MI, \"auc\": GATE_AUC, \"abs_corr\": GATE_CORR},\n",
        "        \"id_col\": id_col,\n",
        "        \"label\": LABEL,\n",
        "    }\n",
        "    with open(os.path.join(RESULTS_DIR, \"fs_summary.json\"), \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "\n",
        "    # Human-readable report\n",
        "    lines = []\n",
        "    lines.append(\"# 1.3.10 — Feature Evaluation & Refinement\\n\")\n",
        "    lines.append(\"## Inputs\\n\")\n",
        "    lines.append(f\"- Source: results/iteration_2/features_v2.csv ({df.shape[0]} rows, {df.shape[1]} cols)\\n\")\n",
        "    lines.append(f\"- Label: {LABEL} | ID: {id_col} | Model: {model_name}\\n\")\n",
        "    lines.append(\"\\n## Filtering\\n\")\n",
        "    lines.append(f\"- Zero-variance removed: {len(zero_var)}\\n\")\n",
        "    lines.append(f\"- Low-variance removed (≤ {VAR_THRESH}): {len(low_var)}\\n\")\n",
        "    lines.append(f\"- After redundancy pruning @ {REDUNDANCY_THRESH}: {len(pruned)}\\n\")\n",
        "    lines.append(\"\\n## Univariate signals (top 15 by MI)\\n\")\n",
        "    lines.append(uni_df.head(15).to_markdown(index=False))\n",
        "    lines.append(\"\\n\\n## Model importances (top 20)\\n\")\n",
        "    lines.append(imp_df.head(20)[[\"mean_importance\",\"std_importance\"]].to_markdown())\n",
        "    lines.append(\"\\n\\n## Permutation importances (top 20)\\n\")\n",
        "    lines.append(perm_df.head(20)[[\"mean_perm\",\"std_perm\"]].to_markdown())\n",
        "    lines.append(\"\\n\\n## Selected features (first pass)\\n\")\n",
        "    lines.append(\"```\")\n",
        "    lines.extend(selected)\n",
        "    lines.append(\"`````\\n\")\n",
        "\n",
        "    report_path = os.path.join(RESULTS_DIR, \"feature_selection_report.md\")\n",
        "    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join(lines))\n",
        "\n",
        "    print(\"[saved] selected_features_v1.txt, fs_* CSVs, and feature_selection_report.md\")\n",
        "\n",
        "else:\n",
        "    # No labels available → produce an unsupervised shortlist based on stability & missingness\n",
        "    print(\"[info] Label not available — running unsupervised selection.\")\n",
        "    usable = [c for c in usable if miss_ratio.get(c, 1.0) <= 0.3]\n",
        "\n",
        "    # Redundancy pruning via Pearson\n",
        "    imputer = SimpleImputer(strategy=\"median\")\n",
        "    X_imp = pd.DataFrame(imputer.fit_transform(df[usable]), columns=usable)\n",
        "    corr_mat = X_imp.corr().abs()\n",
        "    np.fill_diagonal(corr_mat.values, 0.0)\n",
        "\n",
        "    REDUNDANCY_THRESH = 0.95\n",
        "    to_drop = set()\n",
        "    for a in usable:\n",
        "        if a in to_drop:\n",
        "            continue\n",
        "        for b in corr_mat.index[(corr_mat.loc[a] >= REDUNDANCY_THRESH)].tolist():\n",
        "            if b == a or b in to_drop:\n",
        "                continue\n",
        "            # drop lower variance\n",
        "            drop = b if df[b].var(skipna=True) < df[a].var(skipna=True) else a\n",
        "            to_drop.add(drop)\n",
        "    pruned = [c for c in usable if c not in to_drop]\n",
        "\n",
        "    selected = pruned[:50]\n",
        "    with open(os.path.join(RESULTS_DIR, \"selected_features_v1.txt\"), \"w\") as f:\n",
        "        for c in selected:\n",
        "            f.write(c + \"\\n\")\n",
        "\n",
        "    report_path = os.path.join(RESULTS_DIR, \"feature_selection_report.md\")\n",
        "    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join([\n",
        "            \"# 1.3.10 — Feature Evaluation & Refinement (Unsupervised)\",\n",
        "            f\"- Source: {FEATS_CSV} ({df.shape[0]} rows)\",\n",
        "            f\"- Selected (top 50 after redundancy): {len(selected)}\",\n",
        "            \"\",\n",
        "            \"First-pass unsupervised shortlist written to selected_features_v1.txt\",\n",
        "        ]))\n",
        "\n",
        "    print(\"[saved] selected_features_v1.txt and feature_selection_report.md (unsupervised)\")\n",
        "\n",
        "# === Optional: quick visuals (each in its own Matplotlib figure) ===\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Missingness top-20\n",
        "mr = miss_ratio.head(20)\n",
        "plt.figure()\n",
        "mr.plot(kind=\"bar\")\n",
        "plt.title(\"Top-20 Missingness Ratio by Feature\")\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Missingness\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# If label, show combined score distribution\n",
        "if LABEL is not None and os.path.exists(os.path.join(RESULTS_DIR, \"fs_combined_scores.csv\")):\n",
        "    combo = pd.read_csv(os.path.join(RESULTS_DIR, \"fs_combined_scores.csv\"))\n",
        "    plt.figure()\n",
        "    pd.Series(combo[\"score\"]).hist(bins=40)\n",
        "    plt.title(\"Distribution of Combined Feature Scores\")\n",
        "    plt.xlabel(\"Score\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"Done.\")\n"
      ]
    }
  ]
}