{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead6d9c0",
   "metadata": {},
   "source": [
    "# 1.2.4.2 Feature Definition & Exploration Plan\n",
    "\n",
    "This notebook defines the feature engineering strategy and exploratory data analysis (EDA) plan for the AB Data Challenge project.\n",
    "\n",
    "## Objectives\n",
    "- Define comprehensive feature families for anomaly detection\n",
    "- Create detailed EDA plan for Iteration 2\n",
    "- Establish data cleaning rules and preprocessing requirements\n",
    "- Plan feature engineering approach for model development\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267043e7",
   "metadata": {},
   "source": [
    "## Feature Families for Anomaly Detection\n",
    "\n",
    "### 1. Temporal Window Features\n",
    "These features capture consumption patterns over different time windows:\n",
    "\n",
    "#### Short-term Windows (1-24 hours)\n",
    "- **Rolling Mean**: 1h, 3h, 6h, 12h, 24h rolling averages\n",
    "- **Rolling Std**: 1h, 3h, 6h, 12h, 24h rolling standard deviations\n",
    "- **Rolling Min/Max**: 1h, 3h, 6h, 12h, 24h rolling minimums and maximums\n",
    "- **Rolling Percentiles**: 25th, 50th, 75th, 90th, 95th percentiles over 24h window\n",
    "\n",
    "#### Medium-term Windows (1-7 days)\n",
    "- **Daily Aggregates**: Mean, median, std, min, max consumption per day\n",
    "- **Daily Patterns**: Hourly consumption patterns within each day\n",
    "- **Weekend vs Weekday**: Different patterns for weekend vs weekday consumption\n",
    "- **Rolling 7-day**: 7-day rolling statistics for trend analysis\n",
    "\n",
    "#### Long-term Windows (1-12 months)\n",
    "- **Weekly Aggregates**: Mean, median, std consumption per week\n",
    "- **Monthly Aggregates**: Mean, median, std consumption per month\n",
    "- **Seasonal Patterns**: Quarterly and seasonal consumption trends\n",
    "- **Year-over-Year**: Comparison with same period previous year\n",
    "\n",
    "### 2. Baseline Features\n",
    "These features establish normal consumption patterns:\n",
    "\n",
    "#### Municipality-specific Baselines\n",
    "- **Historical Mean**: Long-term average consumption per municipality\n",
    "- **Historical Median**: Long-term median consumption per municipality\n",
    "- **Historical Std**: Long-term standard deviation per municipality\n",
    "- **Percentile Baselines**: 25th, 50th, 75th, 90th, 95th percentiles\n",
    "\n",
    "#### Time-based Baselines\n",
    "- **Hourly Baseline**: Average consumption for each hour of day\n",
    "- **Daily Baseline**: Average consumption for each day of week\n",
    "- **Monthly Baseline**: Average consumption for each month of year\n",
    "- **Seasonal Baseline**: Average consumption for each season\n",
    "\n",
    "### 3. Variability Features\n",
    "These features measure consumption variability and stability:\n",
    "\n",
    "#### Statistical Variability\n",
    "- **Coefficient of Variation**: Std/Mean ratio for different time windows\n",
    "- **Range**: Max - Min consumption over time windows\n",
    "- **Interquartile Range**: 75th - 25th percentile range\n",
    "- **Skewness**: Distribution asymmetry measure\n",
    "- **Kurtosis**: Distribution tail heaviness measure\n",
    "\n",
    "#### Stability Measures\n",
    "- **Consumption Stability**: Variance in consumption over time\n",
    "- **Pattern Consistency**: Consistency of daily/weekly patterns\n",
    "- **Trend Stability**: Stability of consumption trends\n",
    "- **Volatility**: Rate of change in consumption\n",
    "\n",
    "### 4. Seasonality Features\n",
    "These features capture seasonal and cyclical patterns:\n",
    "\n",
    "#### Cyclical Components\n",
    "- **Hour of Day**: Cyclical encoding of hour (sin/cos)\n",
    "- **Day of Week**: Cyclical encoding of weekday (sin/cos)\n",
    "- **Day of Month**: Cyclical encoding of day in month\n",
    "- **Month of Year**: Cyclical encoding of month (sin/cos)\n",
    "- **Day of Year**: Cyclical encoding of day in year\n",
    "\n",
    "#### Seasonal Indicators\n",
    "- **Season**: Spring, Summer, Fall, Winter indicators\n",
    "- **Quarter**: Q1, Q2, Q3, Q4 indicators\n",
    "- **Holiday Periods**: Special holiday and vacation periods\n",
    "- **Weather Season**: Hot/Cold weather periods\n",
    "\n",
    "### 5. Aggregate Features\n",
    "These features combine multiple data points:\n",
    "\n",
    "#### Time-based Aggregates\n",
    "- **Daily Totals**: Total consumption per day\n",
    "- **Weekly Totals**: Total consumption per week\n",
    "- **Monthly Totals**: Total consumption per month\n",
    "- **Peak Consumption**: Maximum consumption in time windows\n",
    "- **Off-peak Consumption**: Minimum consumption in time windows\n",
    "\n",
    "#### Statistical Aggregates\n",
    "- **Moving Averages**: Different window sizes for trend analysis\n",
    "- **Exponential Smoothing**: Weighted averages with decay\n",
    "- **Cumulative Sums**: Running totals over time\n",
    "- **Growth Rates**: Period-over-period growth rates\n",
    "\n",
    "### 6. Data Quality Features\n",
    "These features help identify data quality issues:\n",
    "\n",
    "#### Completeness Features\n",
    "- **Missing Value Count**: Number of missing values in time windows\n",
    "- **Missing Value Rate**: Percentage of missing values\n",
    "- **Data Availability**: Percentage of available data points\n",
    "- **Gap Length**: Length of consecutive missing value periods\n",
    "\n",
    "#### Consistency Features\n",
    "- **Value Consistency**: Consistency of values within time windows\n",
    "- **Pattern Consistency**: Consistency of consumption patterns\n",
    "- **Timestamp Consistency**: Consistency of timestamp intervals\n",
    "- **Range Consistency**: Consistency of value ranges\n",
    "\n",
    "#### Anomaly Indicators\n",
    "- **Negative Value Count**: Number of negative consumption values\n",
    "- **Zero Value Count**: Number of zero consumption values\n",
    "- **Extreme Value Count**: Number of extreme consumption values\n",
    "- **Outlier Indicators**: Statistical outlier detection flags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3107b9cd",
   "metadata": {},
   "source": [
    "## EDA Plan for Iteration 2\n",
    "\n",
    "### 1. Data Coverage Analysis\n",
    "- **Temporal Coverage**: Analyze data availability across time periods\n",
    "- **Municipality Coverage**: Assess data completeness by municipality\n",
    "- **Seasonal Coverage**: Evaluate data availability across seasons\n",
    "- **Gap Analysis**: Identify and quantify data gaps and missing periods\n",
    "\n",
    "### 2. Distribution Analysis\n",
    "- **Consumption Distributions**: Analyze consumption value distributions by municipality\n",
    "- **Temporal Distributions**: Examine consumption patterns across different time periods\n",
    "- **Outlier Analysis**: Identify and analyze extreme consumption values\n",
    "- **Normality Tests**: Assess distribution normality and transformation needs\n",
    "\n",
    "### 3. Stability Analysis\n",
    "- **Trend Analysis**: Identify long-term consumption trends\n",
    "- **Seasonality Analysis**: Detect seasonal patterns and cycles\n",
    "- **Volatility Analysis**: Measure consumption volatility over time\n",
    "- **Pattern Consistency**: Assess consistency of consumption patterns\n",
    "\n",
    "### 4. Correlation Analysis\n",
    "- **Feature Correlations**: Analyze correlations between different features\n",
    "- **Temporal Correlations**: Examine autocorrelations and lag relationships\n",
    "- **Cross-Municipality Correlations**: Identify correlations between municipalities\n",
    "- **External Factor Correlations**: Explore correlations with external factors\n",
    "\n",
    "### 5. Anomaly Pattern Analysis\n",
    "- **Anomaly Frequency**: Analyze frequency and patterns of anomalies\n",
    "- **Anomaly Clustering**: Identify clusters and patterns in anomalous data\n",
    "- **Anomaly Severity**: Categorize anomalies by severity and impact\n",
    "- **Anomaly Context**: Analyze context and conditions surrounding anomalies\n",
    "\n",
    "### 6. Feature Engineering Validation\n",
    "- **Feature Importance**: Assess importance of different feature families\n",
    "- **Feature Stability**: Evaluate stability of engineered features\n",
    "- **Feature Interactions**: Identify important feature interactions\n",
    "- **Feature Redundancy**: Detect and address redundant features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ccae0d",
   "metadata": {},
   "source": [
    "## Handover Notes: Cleaning Rules â†’ Feature Engineering\n",
    "\n",
    "### Data Cleaning Rules for Iteration 2\n",
    "\n",
    "#### 1. Missing Value Handling\n",
    "- **Strategy**: Forward fill for short gaps (< 6 hours), interpolation for medium gaps (6-24 hours), municipality-specific baseline for long gaps (> 24 hours)\n",
    "- **Validation**: Flag records with missing values for quality assessment\n",
    "- **Documentation**: Track missing value patterns and imputation methods\n",
    "\n",
    "#### 2. Negative Value Treatment\n",
    "- **Identification**: Flag all negative consumption values as data quality issues\n",
    "- **Treatment**: Replace with municipality-specific median or set to zero\n",
    "- **Validation**: Cross-check with meter readings and maintenance records\n",
    "- **Documentation**: Log all negative value corrections\n",
    "\n",
    "#### 3. Outlier Detection and Treatment\n",
    "- **Statistical Outliers**: Use IQR method (Q3 + 1.5*IQR) for initial detection\n",
    "- **Business Logic Outliers**: Flag values > 3x municipality-specific 95th percentile\n",
    "- **Treatment**: Cap outliers at 99th percentile or investigate further\n",
    "- **Validation**: Manual review of extreme outliers\n",
    "\n",
    "#### 4. Timestamp Validation\n",
    "- **Consistency**: Ensure hourly intervals are consistent\n",
    "- **Completeness**: Identify and flag missing time periods\n",
    "- **Validation**: Check for future dates and invalid timestamps\n",
    "- **Correction**: Interpolate missing timestamps or flag for exclusion\n",
    "\n",
    "#### 5. Municipality-specific Rules\n",
    "- **Barcelona**: Higher consumption thresholds, more complex patterns\n",
    "- **L'Hospitalet**: Moderate consumption patterns, industrial areas\n",
    "- **Santa Coloma**: Lower consumption, residential focus\n",
    "- **Viladecans**: Mixed patterns, smaller dataset\n",
    "\n",
    "### Feature Engineering Pipeline\n",
    "\n",
    "#### Phase 1: Basic Features (Week 1)\n",
    "1. **Temporal Features**: Hour, day, month, season extraction\n",
    "2. **Rolling Statistics**: 1h, 6h, 24h rolling means and standard deviations\n",
    "3. **Baseline Features**: Municipality-specific historical averages\n",
    "4. **Data Quality Features**: Missing value flags, outlier indicators\n",
    "\n",
    "#### Phase 2: Advanced Features (Week 2)\n",
    "1. **Seasonality Features**: Cyclical encoding, seasonal indicators\n",
    "2. **Variability Features**: Coefficient of variation, stability measures\n",
    "3. **Aggregate Features**: Daily/weekly/monthly totals and patterns\n",
    "4. **Interaction Features**: Municipality Ã— time interactions\n",
    "\n",
    "#### Phase 3: Model-specific Features (Week 3)\n",
    "1. **Anomaly Features**: Distance from baseline, z-scores\n",
    "2. **Trend Features**: Growth rates, trend indicators\n",
    "3. **Pattern Features**: Consistency measures, pattern deviations\n",
    "4. **Ensemble Features**: Combined feature scores\n",
    "\n",
    "### Quality Assurance\n",
    "\n",
    "#### Feature Validation\n",
    "- **Range Checks**: Ensure features are within expected ranges\n",
    "- **Consistency Checks**: Validate feature consistency across time\n",
    "- **Correlation Analysis**: Identify and address feature redundancy\n",
    "- **Performance Impact**: Monitor feature engineering impact on model performance\n",
    "\n",
    "#### Documentation Requirements\n",
    "- **Feature Definitions**: Clear documentation of all engineered features\n",
    "- **Transformation Logic**: Document all data transformations\n",
    "- **Validation Results**: Record all validation and quality checks\n",
    "- **Performance Metrics**: Track feature engineering impact on model performance\n",
    "\n",
    "### Success Criteria\n",
    "\n",
    "#### Technical Criteria\n",
    "- **Feature Completeness**: All planned features implemented and validated\n",
    "- **Data Quality**: <5% missing values, <1% negative values, <2% outliers\n",
    "- **Feature Stability**: Features stable across different time periods\n",
    "- **Performance Impact**: Features improve model performance by >10%\n",
    "\n",
    "#### Business Criteria\n",
    "- **Interpretability**: Features are interpretable and explainable\n",
    "- **Scalability**: Feature engineering pipeline can handle larger datasets\n",
    "- **Maintainability**: Code is well-documented and maintainable\n",
    "- **Reproducibility**: Results are reproducible across different runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Simple deterministic plot if data is available\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Try to load data for visualization\n",
    "try:\n",
    "    data_path = '../data/dataset_sample.parquet'\n",
    "    if os.path.exists(data_path):\n",
    "        df = pd.read_parquet(data_path)\n",
    "        print(\"âœ“ Data loaded successfully for visualization\")\n",
    "        \n",
    "        # Set up the plotting style\n",
    "        plt.style.use('default')\n",
    "        sns.set_palette(\"husl\")\n",
    "        \n",
    "        # Create a simple consumption distribution plot\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('Water Consumption Data Overview', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Plot 1: Consumption distribution by municipality\n",
    "        if 'municipality' in df.columns and 'consumption' in df.columns:\n",
    "            consumption_clean = df[df['consumption'].notna() & (df['consumption'] > 0)]\n",
    "            if len(consumption_clean) > 0:\n",
    "                consumption_clean.boxplot(column='consumption', by='municipality', ax=axes[0,0])\n",
    "                axes[0,0].set_title('Consumption Distribution by Municipality')\n",
    "                axes[0,0].set_xlabel('Municipality')\n",
    "                axes[0,0].set_ylabel('Consumption')\n",
    "                axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Plot 2: Time series of consumption (sample)\n",
    "        if 'timestamp' in df.columns and 'consumption' in df.columns:\n",
    "            # Sample data for visualization (first 1000 points)\n",
    "            sample_data = df.head(1000)\n",
    "            sample_data = sample_data[sample_data['consumption'].notna()]\n",
    "            if len(sample_data) > 0:\n",
    "                axes[0,1].plot(sample_data['timestamp'], sample_data['consumption'], alpha=0.7)\n",
    "                axes[0,1].set_title('Consumption Time Series (Sample)')\n",
    "                axes[0,1].set_xlabel('Time')\n",
    "                axes[0,1].set_ylabel('Consumption')\n",
    "                axes[0,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Plot 3: Missing values by municipality\n",
    "        if 'municipality' in df.columns:\n",
    "            missing_by_municipality = df.groupby('municipality').apply(lambda x: x.isnull().sum().sum())\n",
    "            missing_by_municipality.plot(kind='bar', ax=axes[1,0])\n",
    "            axes[1,0].set_title('Missing Values by Municipality')\n",
    "            axes[1,0].set_xlabel('Municipality')\n",
    "            axes[1,0].set_ylabel('Missing Values Count')\n",
    "            axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Plot 4: Data availability over time\n",
    "        if 'timestamp' in df.columns:\n",
    "            # Group by month and count records\n",
    "            df['year_month'] = df['timestamp'].dt.to_period('M')\n",
    "            monthly_counts = df.groupby('year_month').size()\n",
    "            monthly_counts.plot(kind='line', ax=axes[1,1])\n",
    "            axes[1,1].set_title('Data Availability Over Time')\n",
    "            axes[1,1].set_xlabel('Month')\n",
    "            axes[1,1].set_ylabel('Record Count')\n",
    "            axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"âœ“ Visualization completed successfully\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âš  Dataset file not found - skipping visualization\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš  Error during visualization: {e}\")\n",
    "    print(\"  This is expected if the dataset is not available or has different structure\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
